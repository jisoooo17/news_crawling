{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 크롤링에 대한 이해\n",
    "# 웹 크롤링은 컴퓨터가 유저대신 \n",
    "# 데이터 열람, 복사, 저장 등의 과정을 진행하는 것이다.\n",
    "# 예매 매크로 프로그램과 유사한 측면이 있으나 \n",
    "# 예매 매크로과 완전히 같은 기능은 없다.\n",
    "\n",
    "# 웹 크롤링엔 크게 정적 크롤링과 동적 크롤링이 있다.\n",
    "\n",
    "# 정적 크롤링: url로 사이트 접근 시 특별한 작업 없이 원하는 데이터 접근가능\n",
    "# 예) 다음뉴스, 다음영화 등\n",
    "\n",
    "# 동적 크롤링: 원하는 데이터 접근 시 유저가 별도의 작업을 해야한다.\n",
    "# 예) 유튜브, 인스타그램 등\n",
    "\n",
    "# 정적 크롤링에 사용되는 라이브러리는 BeautifulSoup 이 있고\n",
    "# 동적 크롤링에 사용되는 라이브러리는 Selenium이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****파싱:\n",
    "# BeautifulSoup 객체를 생성하려면 HTML 또는 XML 문자열과 \n",
    "# 파서를 전달해야 합니다. 일반적으로 'html.parser'를 사용합니다.\n",
    "# 파서 = 데이터를 분석하는 해독기\n",
    "# 사이트 url을 html_doc변수에 담아서 선언\n",
    "# 사이트 주소를 요청하는 라이브러리\n",
    "\n",
    "# 1. 라이브러리 호출\n",
    "import urllib.request as req\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 2. 원하는 url 주소 담아서 열리는지 확인\n",
    "url = \"http://media.daum.net\"\n",
    "# 위 주소를 열어봐서(다음 서버에 정보요청) 잘 열리는 경우에만 정보 열람\n",
    "res = req.urlopen(url)\n",
    "source = res.read()\n",
    "\n",
    "# 3. 한글깨짐 방지\n",
    "# 한글을 지원하는 유니코드입니다.\n",
    "source = source.decode('utf-8')\n",
    "\n",
    "# 4. 데이터 해석 (parsing)\n",
    "# BeautifulSoup에서 본 사이트는 html문서라는 것을 알려줌\n",
    "html = BeautifulSoup(source, 'html.parser')\n",
    "# ***파악한 패턴을 적용하여 원하는 정보를 atags 변수에 저장 합니다.\n",
    "atags = html.select('a[class=link_txt]')\n",
    "\n",
    "# 일단 결과를 테스트 출력\n",
    "# atags 변수에 원하는 데이터가 있음을 확인\n",
    "# print(atags, len(atags))\n",
    "\n",
    "\n",
    "# 뉴스 내용만 수집하려면?\n",
    "# result_data 변수에 빈 리스트 자료구조를 선언 (문자열 데이터 만을 추출하면 된다.)\n",
    "result_data = []\n",
    "\n",
    "cnt = 0 # 총 뉴스 헤드라인의 개수도 세고싶어서 cnt 변수 선언\n",
    "# 크롤링한 전체 데이터에서 개별 데이터 호출\n",
    "# for문으로 크롤링 데이터 셋에서 개별문장 하나씩 호출\n",
    "for ii in atags:\n",
    "    cnt += 1\n",
    "    # 데이터를 문자열로 변환 (전체 문장에서 문자열 데이터만 추출함)\n",
    "    atag_str = str(ii.string)\n",
    "    # 걸러진 문자열 데이터를 준비한 리스트 자료구조에 담습니다\n",
    "    result_data.append(atag_str.strip()) # 문장좌우에 불필요한 여백은 strip으로 제거\n",
    "\n",
    "print(result_data, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "# 뉴스 데이터 자체는 불필요한 특수기호, 따옴표, 부적절한 띄어쓰기 등으로\n",
    "# 자연어 데이터가 일관성이 떨어진다.\n",
    "# 즉, 단어를 세서 키워드 분석 등의 자연어 처리 작업이 불가 하므로\n",
    "# 문자데이터를 전처리 하여 데이터 클리닝을 진행하여야 한다.\n",
    "\n",
    "\n",
    "# 텍스트 전처리 순서\n",
    "# 1. 텍스트 전처리 관련 (정규 표현식) 라이브러리 호출\n",
    "import re\n",
    "\n",
    "# 2. 텍스트 전처리 함수 만들기\n",
    "# 함수에서 입력값을 받아서 처리하겠다는 의미로 괄호안에 input_data라는 변수 선언\n",
    "def clean_text(ㅋㅋㅋ):\n",
    "    # 문장부호 제거기능 추가 (sub라는 명령어는 교체한다는 의미)\n",
    "    text_string_re1 = re.sub('[,.?!:\\'\\\";]', '', ㅋㅋㅋ)\n",
    "    # 특수문자 제거기능 추가\n",
    "    text_string_re2 = re.sub('[!@#$%^&*()]|[0-9]', '', text_string_re1)\n",
    "    # 영문 대,소문자 --> 영문 소문자로 통일 (소문자 변환 lower함수 사용)\n",
    "    text_string_re3 = text_string_re2.lower()\n",
    "    # 통일된 영문 데이터를 없애기\n",
    "    text_string_re4 = re.sub('[a-z]', '', text_string_re3)\n",
    "    # 불필요한 공백제거 \n",
    "    # (split함수 통해서 단어마다 별도의 데이터로 인식 후, 불필요한 여백제거)\n",
    "    text_string_re5 = ' '.join(text_string_re4.split())\n",
    "    return text_string_re5\n",
    "\n",
    "# 텍스트 함수 사용\n",
    "# 전처리 후 깨끗해진 단어 데이터를 넣을 리스트 자료형 데이터셋을 선언합니다.\n",
    "clean_text2 = []\n",
    "# 이전의 결과 셋에서 개별 데이터를 호출해서 \n",
    "# clean_text함수에 넣고 데이터 전처리\n",
    "for jj in result_data:\n",
    "    clean_text2.append(clean_text(jj))\n",
    "\n",
    "# clean_text2 = [clean_text(jj) for jj in result_data]\n",
    "\n",
    "print(\"저희 결과는\")\n",
    "print(clean_text2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 빈도파악 (단어 수 세기)\n",
    "\n",
    "# 단어 수 셀 때 딕셔너리 자료구조가 필요하다. \n",
    "# 왜? key와 value로 단어와 단어 개수를 표시해야 하므로\n",
    "word_count = {}\n",
    "\n",
    "# 단어 수 셀 때 주의사항: \n",
    "# 각 문장안에 단어가 있으므로 2중 for문 구조가 필요\n",
    "# 바깥 for문이 개별 문장이고, \n",
    "# 안쪽 for문이 그 문장 안에 단어이다.\n",
    "\n",
    "#  전처리 데이터셋 에서 text라는 이름으로 문장 하나씩 끄집어 냄\n",
    "for text in clean_text2:\n",
    "    # 끄집어낸 문장에서 단어 하나씩 추출\n",
    "    # split함수가 없으면 단어의 글자로 전부 세버린다. split을 써야\n",
    "    # 문장 안에서 단어로 인식 가능 \n",
    "    for word in text.split(): \n",
    "        # 딕셔너리 자료구조에서 단어를 key값으로 놓고\n",
    "        # get함수를 이용해서 같은 데이터가 들올 때마다 1씩 증가\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 전처리 (글자데이터에 의미부여)\n",
    "# 2회이상 출현단어 + 2~4자 단어만 선정\n",
    "\n",
    "new_word_count = {}\n",
    "# 딕셔너리 구조의 items함수 이용해서 단어의 빈도수와 단어정보를\n",
    "# 동시에 접근 하였고 개별 원소에서 변수 2개 설정 (word, cnt)\n",
    "for word, cnt in word_count.items():\n",
    "    # 2회 이상출현 & 단어 글자 수 2~4글자 사이\n",
    "    if cnt >=2 and len(word) >= 2 and len(word) <=4:\n",
    "        print(word, \"->\", word_count[word])\n",
    "        # 딕셔너리 자료구조에서 단어를 key값으로 놓고\n",
    "        # get함수를 이용해서 같은 데이터가 들올 때마다 1씩 증가\n",
    "        new_word_count[word] = new_word_count.get(word, cnt)\n",
    "\n",
    "print(new_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통계자료 작성\n",
    "\n",
    "from collections import Counter \n",
    "# 상위 몇위 등의 통계를 만드는 Counter라는 라이브러리에 데이터 입력\n",
    "count_result = Counter(new_word_count)\n",
    "# 단어 빈도 수 기준, 상위 5단어를 뽑아서 top5_word 변수에 저장\n",
    "top5_word = count_result.most_common(5)\n",
    "print(top5_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Arial Unicode MS'  \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 그래프 데이터\n",
    "words = []\n",
    "counts = []\n",
    "\n",
    "for word, count in top5_word:\n",
    "    words.append(word)\n",
    "    counts.append(count)\n",
    "\n",
    "# 선그래프 그리기\n",
    "plt.plot(words, counts)\n",
    "plt.show()\n",
    "\n",
    "# 막대그래프 그리기\n",
    "plt.bar(words, counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
